{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from modules.Utils.utils import loadFromDB\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from multiprocess import cpu_count\n",
    "\n",
    "from modules.Utils.utils import loadFromDB, strategyTester, getFearAndGreedIndicator,computeStochasticLinearRegression,computeEMD\n",
    "from modules.Utils.indicators import computeSuperTrend, addIndicators, computeLaggingLinearRegression, computeTrixIndicator, generateDatesFeatures\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currencies = ['BTC','ETH','ADA','AAVE','ALGO','EGLD','ETH','LINK','DOT','SOL','UNI','XRP','AVAX','AXS','NEAR','MATIC']\n",
    "print(f'Total currencies : {len(currencies)}')\n",
    "def getCurrencies(symbol:str):\n",
    "    df_copy = loadFromDB(symbol,'12h')\n",
    "    \n",
    "    #df_copy = computeLaggingLinearRegression(df_copy,window=10,filter_ceof=False, derivative=False)\n",
    "    df_copy = addIndicators(df_copy,derivative=True, b_engulfings=True)\n",
    "    df_copy = generateDatesFeatures(df_copy)\n",
    "    #df_copy = getFearAndGreedIndicator(df_copy)\n",
    "    df_copy = computeTrixIndicator(df_copy, col='Close')\n",
    "    df_copy['Return'] =df_copy.Close.pct_change()\n",
    "    df_copy['Target'] = df_copy.Return.shift(-1)\n",
    "    df_copy.drop(columns=['Timestamp'],inplace=True)\n",
    "    df_copy.dropna(inplace=True)\n",
    "    df_copy['Target'] =  df_copy['Target'].apply(lambda x: 1 if x>=0 else 0)\n",
    "    #df_copy.drop(columns=['Timestamp','B_MLR_coefs_filtered','B_MLR_coefs_filtered_diff','Prev_B_MLR_coefs_filtered_diff'],inplace=True)\n",
    "    print(f'{symbol} : {df_copy.shape}')\n",
    "    return df_copy.dropna()\n",
    "\n",
    "def scaleDfs(df:pd.DataFrame):\n",
    "    y = df.Target.values.reshape(-1,1)\n",
    "    X = df.drop(columns=['Target'])\n",
    "    \n",
    "    #X_scaled = PCA(n_components=15).fit_transform(StandardScaler().fit_transform(X))\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    return {'X':X_scaled,\n",
    "            'y':y} \n",
    "\n",
    "def main(symbol:str):\n",
    "    return scaleDfs(getCurrencies(symbol))\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=cpu_count()) as executor:\n",
    "    processes = [executor.submit(main, cur) for cur in currencies]\n",
    "\n",
    "x_n_y = [task.result() for task in as_completed(processes)]\n",
    "\n",
    "print('Splitting done !')\n",
    "\n",
    "X = np.vstack(tuple([x['X'] for x in x_n_y]))\n",
    "y = np.vstack(tuple([x['y'] for x in x_n_y]))\n",
    "#np.save('./data/X.npy',X)\n",
    "#np.save('./data/y.npy',y)\n",
    "print('Saving done !')\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyts.datasets import load_gunpoint\n",
    "from pyts.image import GramianAngularField, MarkovTransitionField\n",
    "\n",
    "transformer = GramianAngularField(method='summation')#MarkovTransitionField(n_bins=20,strategy='normal')#\n",
    "X_new = transformer.transform(X)\n",
    "#X_new_2 = np.array([x.reshape(15,15,1) for x in X_new ])\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from time import sleep\n",
    "from IPython import display\n",
    "\n",
    "#fig, ax = plt.subplots(1, figsize=(25,8))\n",
    "for i in X_new:\n",
    "    plt.imshow(i, cmap='rainbow', origin='lower')\n",
    "    plt.show()\n",
    "    display.clear_output(wait=True)\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten, Conv1D,Conv2D, GRU, InputLayer, RepeatVector, TimeDistributed, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.activations import relu\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError, BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((35, 35)))\n",
    "model.add(LSTM(units = 64, return_sequences = True))\n",
    "model.add(LSTM(units = 32, return_sequences = True))\n",
    "for dilation_rate in (1,2,4,8,16,23):\n",
    "    model.add(Conv1D(filters=32,kernel_size=2,dilation_rate=dilation_rate,strides=1,padding='causal',activation=keras.activations.relu))\n",
    "model.add(Conv1D(filters=1,kernel_size=2)) \n",
    "\n",
    "#model.add(InputLayer((15, 15,1)))\n",
    "#model.add(Conv2D(filters=32, activation='relu',kernel_size=2)) \n",
    "#model.add(MaxPooling2D((2,2)))\n",
    "#model.add(Conv2D(filters=64, activation='relu',kernel_size=2)) \n",
    "#model.add(MaxPooling2D(2))\n",
    "#model.add(Conv2D(filters=64, activation='relu',kernel_size=1)) \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 64,activation=keras.activations.relu))\n",
    "model.add(Dense(units = 1,activation=keras.activations.sigmoid))\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate=0.001), loss = 'binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_new,\n",
    "          y,\n",
    "          epochs=20,\n",
    "          shuffle=True,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                                        verbose=1,\n",
    "                                                       patience=8,\n",
    "                                                       min_delta=0.001,\n",
    "                                                       mode='max',\n",
    "                                                       restore_best_weights=True)],\n",
    "          use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "\n",
    "class estimator:\n",
    "  _estimator_type = ''\n",
    "  classes_=[]\n",
    "  def __init__(self, model, classes):\n",
    "    self.model = model\n",
    "    self._estimator_type = 'classifier'\n",
    "    self.classes_ = classes\n",
    "  def predict(self, X):\n",
    "    y_prob= self.model.predict(X)\n",
    "    y_pred = y_prob.argmax(axis=1)\n",
    "    return y_pred\n",
    "\n",
    "classifier = estimator(model, ['0','1'])\n",
    "plot_confusion_matrix(estimator=classifier, X=X_new_2, y_true=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyts.image import GramianAngularField\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "transformer = MarkovTransitionField(n_bins=8,strategy='normal')#GramianAngularField(image_size=30, method='summation')\n",
    "X_new = transformer.transform(X)\n",
    "\n",
    "def convert_img(idx):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    try:\n",
    "        fname = f'./imgs/{idx}.png'\n",
    "        if os.path.exists(fname):\n",
    "            return\n",
    "    except:\n",
    "        return\n",
    "    ax.imshow(X_new[idx], cmap='rainbow', origin='lower')\n",
    "    ax.set_title('')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    fig.savefig(fname, bbox_inches='tight',pad_inches=0,transparent=True)\n",
    "    \n",
    "p = Pool(cpu_count())\n",
    "_ = p.map(convert_img, (i for i in range(X_new.shape[0])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d58cacdab5e87910af5fd11a0a6d597df11e0910bae80574c4c81b52a6810385"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
