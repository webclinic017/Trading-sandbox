{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tweepy langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1565631262760501248</td>\n",
       "      <td>Deer coin fast in jumping the crypto \\n#BNB #B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1565631260655239171</td>\n",
       "      <td>@B055Lady_Elle @POODLETOKEN First dominant, un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1565631259694743552</td>\n",
       "      <td>@facugambande First dominant, unique and commu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1565631258188734464</td>\n",
       "      <td>@chaeiyo_0 @RichQuack The King Of Memes is her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1565631257509249024</td>\n",
       "      <td>#btc @Acyn: 'McCarthy: The electric cord of li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text\n",
       "0  1565631262760501248  Deer coin fast in jumping the crypto \\n#BNB #B...\n",
       "1  1565631260655239171  @B055Lady_Elle @POODLETOKEN First dominant, un...\n",
       "2  1565631259694743552  @facugambande First dominant, unique and commu...\n",
       "3  1565631258188734464  @chaeiyo_0 @RichQuack The King Of Memes is her...\n",
       "4  1565631257509249024  #btc @Acyn: 'McCarthy: The electric cord of li..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "client = tweepy.Client(bearer_token=\"AAAAAAAAAAAAAAAAAAAAAIHQcQEAAAAAltFqxFhiitQ6AT8R9LP8mX%2F9y8w%3DSTDzL94lipFbvKOqaLMNTFQKx2Tf0Y3fODsrwq0bjSkggdF5fY\")\n",
    "\n",
    "tweets = client.search_recent_tweets(\"(#bitcoin OR #Bitcoin OR #BTC OR #btc OR #cryptocurrencies) -is:retweet lang:en\",max_results=100,).data\n",
    "tweets_df = pd.DataFrame([tweet.data for tweet in tweets])\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanTweets(txt):\n",
    "    txt = str(txt)\n",
    "    txt = re.sub(r'#','',txt)\n",
    "    txt = re.sub(r'\\n','',txt)\n",
    "    txt = re.sub(r'https?:\\/\\/\\S+','',txt)\n",
    "    txt = re.sub(r'@','',txt)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', txt).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1565631262760501248</td>\n",
       "      <td>deer coin fast in jumping the crypto bnb binan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1565631260655239171</td>\n",
       "      <td>b055lady_elle poodletoken first dominant, uniq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1565631259694743552</td>\n",
       "      <td>facugambande first dominant, unique and commun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1565631258188734464</td>\n",
       "      <td>chaeiyo_0 richquack the king of memes is here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1565631257509249024</td>\n",
       "      <td>btc acyn: 'mccarthy: the electric cord of libe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text\n",
       "0  1565631262760501248  deer coin fast in jumping the crypto bnb binan...\n",
       "1  1565631260655239171  b055lady_elle poodletoken first dominant, uniq...\n",
       "2  1565631259694743552  facugambande first dominant, unique and commun...\n",
       "3  1565631258188734464  chaeiyo_0 richquack the king of memes is here ...\n",
       "4  1565631257509249024  btc acyn: 'mccarthy: the electric cord of libe..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.text = tweets_df.text.apply(cleanTweets)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.12.1-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
      "\u001b[K     |█████▍                          | 129.4 MB 14.3 MB/s eta 0:00:46  |                                | 624 kB 4.1 MB/s eta 0:03:09     |▍                               | 9.5 MB 124 kB/s eta 1:42:31     |▌                               | 11.0 MB 134 kB/s eta 1:34:57     |▌                               | 11.4 MB 134 kB/s eta 1:34:55     |▊                               | 17.0 MB 134 kB/s eta 1:34:13     |█▍                              | 34.4 MB 125 kB/s eta 1:38:48     |█▊                              | 42.7 MB 122 kB/s eta 1:39:58     |██▎                             | 54.6 MB 5.1 MB/s eta 0:02:22     |██▍                             | 58.5 MB 5.1 MB/s eta 0:02:22     |███▏                            | 77.0 MB 124 kB/s eta 1:33:46     |███▏                            | 77.5 MB 124 kB/s eta 1:33:42     |███▌                            | 85.2 MB 121 kB/s eta 1:34:31     |███▉                            | 93.7 MB 6.9 MB/s eta 0:01:39     |████                            | 95.4 MB 24.1 MB/s eta 0:00:29     |████                            | 98.0 MB 24.1 MB/s eta 0:00:29     |█████                           | 121.5 MB 10.0 MB/s eta 0:01:06^C\n",
      "\n",
      "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import tqdm\n",
    "\n",
    "# create a tokenizer object\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "# fetch the pretrained model \n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "def sentim_analyzer(df, tokenizer, model):\n",
    "    ''' Given a df that contains a column 'headline' with article healine texts, it runs inference on the healine with the 'model' (FinBert) \n",
    "       and inserts output sentiment features into the dataframe in the respective columns (Positive_sentim, Negative_sentim, Neutral_sentim)\n",
    "       \n",
    "        Parameters :\n",
    "          df : A dataframe that contains headlines in a column called 'headline' . \n",
    "          tokenizer(AutoTokenizer object) : A pre-processing tokenizer object from Hugging Face lib. \n",
    "          model (AutoModelForSequenceClassification object) : A hugging face transformer model.     \n",
    "          \n",
    "          returns df : The initial dataframe with the 3 sentiment features as columns for each headline'''\n",
    "    \n",
    "    for i in df.index :\n",
    "        try:\n",
    "            headline = df.loc[i, 'text']\n",
    "        except:\n",
    "            return print(' \\'headline\\' column might be missing from dataframe')\n",
    "        # Pre-process input phrase\n",
    "        input = tokenizer(headline, padding = True, truncation = True, return_tensors='pt')\n",
    "        # Estimate output\n",
    "        output = model(**input)\n",
    "        # Pass model output logits through a softmax layer.\n",
    "        predictions =  torch.nn.functional.softmax(output.logits, dim=-1)\n",
    "        df.loc[i, 'Positive'] = predictions[0][0].tolist()\n",
    "        df.loc[i, 'Negative'] = predictions[0][1].tolist()\n",
    "        df.loc[i, 'Neutral']  = predictions[0][2].tolist()\n",
    "    # rearrange column order\n",
    "    try:\n",
    "        df = df[['date', 'stock', 'Open', 'Close', 'Volume',  'headline', 'Positive', 'Negative', 'Neutral','Price_change']]\n",
    "    except:\n",
    "        pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1565631262760501248</td>\n",
       "      <td>deer coin fast in jumping the crypto bnb binan...</td>\n",
       "      <td>0.212210</td>\n",
       "      <td>0.018872</td>\n",
       "      <td>0.768918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1565631260655239171</td>\n",
       "      <td>b055lady_elle poodletoken first dominant, uniq...</td>\n",
       "      <td>0.324472</td>\n",
       "      <td>0.007769</td>\n",
       "      <td>0.667759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1565631259694743552</td>\n",
       "      <td>facugambande first dominant, unique and commun...</td>\n",
       "      <td>0.395163</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.597240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1565631258188734464</td>\n",
       "      <td>chaeiyo_0 richquack the king of memes is here ...</td>\n",
       "      <td>0.218423</td>\n",
       "      <td>0.010883</td>\n",
       "      <td>0.770694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1565631257509249024</td>\n",
       "      <td>btc acyn: 'mccarthy: the electric cord of libe...</td>\n",
       "      <td>0.123619</td>\n",
       "      <td>0.015842</td>\n",
       "      <td>0.860539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1565630999769550860</td>\n",
       "      <td>shannonsheriff1 first dominant, unique and com...</td>\n",
       "      <td>0.354394</td>\n",
       "      <td>0.007740</td>\n",
       "      <td>0.637866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1565630998460518400</td>\n",
       "      <td>airdropstario great project to earn $kiss. tha...</td>\n",
       "      <td>0.378834</td>\n",
       "      <td>0.009263</td>\n",
       "      <td>0.611903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1565630998418804736</td>\n",
       "      <td>siksparjonaks1 solrarity_ y00tsnft obendersmar...</td>\n",
       "      <td>0.285853</td>\n",
       "      <td>0.010816</td>\n",
       "      <td>0.703331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1565630997982597120</td>\n",
       "      <td>martiniguyyt gm. make your smartest financial ...</td>\n",
       "      <td>0.046597</td>\n",
       "      <td>0.022341</td>\n",
       "      <td>0.931062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1565630989648691200</td>\n",
       "      <td>tkralow bitcoin bullish</td>\n",
       "      <td>0.143571</td>\n",
       "      <td>0.044296</td>\n",
       "      <td>0.812134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "0   1565631262760501248  deer coin fast in jumping the crypto bnb binan...   \n",
       "1   1565631260655239171  b055lady_elle poodletoken first dominant, uniq...   \n",
       "2   1565631259694743552  facugambande first dominant, unique and commun...   \n",
       "3   1565631258188734464  chaeiyo_0 richquack the king of memes is here ...   \n",
       "4   1565631257509249024  btc acyn: 'mccarthy: the electric cord of libe...   \n",
       "..                  ...                                                ...   \n",
       "95  1565630999769550860  shannonsheriff1 first dominant, unique and com...   \n",
       "96  1565630998460518400  airdropstario great project to earn $kiss. tha...   \n",
       "97  1565630998418804736  siksparjonaks1 solrarity_ y00tsnft obendersmar...   \n",
       "98  1565630997982597120  martiniguyyt gm. make your smartest financial ...   \n",
       "99  1565630989648691200                            tkralow bitcoin bullish   \n",
       "\n",
       "    Positive  Negative   Neutral  \n",
       "0   0.212210  0.018872  0.768918  \n",
       "1   0.324472  0.007769  0.667759  \n",
       "2   0.395163  0.007597  0.597240  \n",
       "3   0.218423  0.010883  0.770694  \n",
       "4   0.123619  0.015842  0.860539  \n",
       "..       ...       ...       ...  \n",
       "95  0.354394  0.007740  0.637866  \n",
       "96  0.378834  0.009263  0.611903  \n",
       "97  0.285853  0.010816  0.703331  \n",
       "98  0.046597  0.022341  0.931062  \n",
       "99  0.143571  0.044296  0.812134  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentim_analyzer(tweets_df, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "tweets_df['Sentiment_pos_neg']=tweets_df.apply(lambda x: 'Positive' if x['Positive']>x['Negative'] else 'Negative', axis=1)\n",
    "tweets_df['Sentiment']=tweets_df.apply(lambda x: ['Positive','Negative','Neutral'][np.array([x['Positive'], x['Negative'], x['Neutral']]).argmax()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    93\n",
       "Negative     7\n",
       "Name: Sentiment_pos_neg, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.Sentiment_pos_neg.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     93\n",
       "Negative     4\n",
       "Positive     3\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'godsunchained  looking for players join our growing card game community. our company is currently expanding and developing in thailand. there is no cost to sign up  website:  blockchain binance '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df_nega = tweets_df.loc[tweets_df['Sentiment']=='Neutral']\n",
    "tweets_df_nega.iloc[10].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def getSubjectivity(txt):\n",
    "    return TextBlob(txt).sentiment.subjectivity\n",
    "tweets_df['subjectivity'] = tweets_df.text.apply(getSubjectivity)\n",
    "def getPolarity(txt):\n",
    "    return TextBlob(txt).sentiment.polarity\n",
    "tweets_df['polarity'] = tweets_df.text.apply(getPolarity)\n",
    "\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweets_df['sentiment_2'] = tweets_df.polarity.apply(lambda score:  \"Negative\" if score<0 else \"Neutral\" if score==0 else \"Positive\")\n",
    "print(tweets_df['sentiment'].value_counts())\n",
    "tweets_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['sentiment_2'].value_counts().to_dict()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d58cacdab5e87910af5fd11a0a6d597df11e0910bae80574c4c81b52a6810385"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
